{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae92308",
   "metadata": {},
   "source": [
    "# MIND Utils Generation\n",
    "많은 뉴스 추천법들이 워드 임베딩, 뉴스 vertical embedding, 뉴스 subvertical embedding, 유저 id 임베딩을 활용하므로 단어 사전, vertical 사전, subvertical 사전과 user id 사전을 만들어 각각을 문자열에서 색인으로 변환할 필요가 있다.   \n",
    "To use the pretrain word embedding, a embedding matrix is generated as the intial weight of the word embedding layer.   \n",
    "- word_dict.pkl: 뉴스 제목에 있는 단어들을 색인으로 변환한다.\n",
    "- word_dict_all.pkl: 뉴스 제목과 요약에 있는 단어들을 색인으로 변환한다.\n",
    "- embedding.npy: `word_dict.pkl`에 있는 단어들의 사전 훈련된 워드 임베딩 행렬\n",
    "- embedding_all.npy: `word_dict_all.pkl`에 있는 단어들의 사전 훈련된 워드 임베딩 행렬\n",
    "- vert_dict.pkl: convert news verticals into indexes.\n",
    "- subvert_dict.pkl: convert news subverticals into indexes.\n",
    "- uid2index.pkl: 유저 id들을 색인으로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf56e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scrapbook as sb\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from tempfile import TemporaryDirectory\n",
    "from recommenders.datasets.mind import download_and_extract_glove, download_mind, extract_mind, load_glove_matrix, word_tokenize\n",
    "from recommenders.datasets.download_utils import unzip_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33f9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 17.0k/17.0k [00:08<00:00, 2.11kKB/s]\n",
      "100%|█████████████████████████████████████| 9.84k/9.84k [00:05<00:00, 1.82kKB/s]\n"
     ]
    }
   ],
   "source": [
    "mind_type = 'demo'\n",
    "word_emb_dim = 300 # should be in [50, 100, 200, 300]\n",
    "\n",
    "tmpdir = TemporaryDirectory()\n",
    "data_path = tmpdir.name\n",
    "train_zip, valid_zip = download_mind(size=mind_type, dest_path=data_path)\n",
    "unzip_file(train_zip, os.path.join(data_path, 'train'), clean_zip_file=False)\n",
    "unzip_file(valid_zip, os.path.join(data_path, 'valid'), clean_zip_file=False)\n",
    "output_path = os.path.join(data_path, 'utils')\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da977b7b",
   "metadata": {},
   "source": [
    "## Prepare utils of news\n",
    "- word dictionary\n",
    "- vertical dictionary\n",
    "- subvertical dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089a22a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertical</th>\n",
       "      <th>subvertical</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "      <td>They seem harmless, but there's a very good re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weather</td>\n",
       "      <td>weathertopstories</td>\n",
       "      <td>It's been Orlando's hottest October ever so fa...</td>\n",
       "      <td>There won't be a chill down to your bones this...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vertical        subvertical  \\\n",
       "0  lifestyle    lifestyleroyals   \n",
       "1       news          newsworld   \n",
       "2     health             voices   \n",
       "3     health            medical   \n",
       "4    weather  weathertopstories   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "2  I Was An NBA Wife. Here's How It Affected My M...   \n",
       "3  How to Get Rid of Skin Tags, According to a De...   \n",
       "4  It's been Orlando's hottest October ever so fa...   \n",
       "\n",
       "                                            abstract  \n",
       "0  Shop the notebooks, jackets, and more that the...  \n",
       "1  Lt. Ivan Molchanets peeked over a parapet of s...  \n",
       "2  I felt like I was a fraud, and being an NBA wi...  \n",
       "3  They seem harmless, but there's a very good re...  \n",
       "4  There won't be a chill down to your bones this...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_table(os.path.join(data_path, 'train', 'news.tsv'),\n",
    "                    names=['newid', 'vertical', 'subvertical', 'title','abstract',\n",
    "                           'url', 'entities in title', 'entities in abstract'],\n",
    "                    usecols=['vertical', 'subvertical', 'title', 'abstract'])\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec1f6fa4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██                                  | 1568/26740 [00:00<00:03, 7833.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Counter({',': 2, 'prince': 2, 'the': 1, 'brands': 1, 'queen': 1, 'elizabeth': 1, 'charles': 1, 'and': 1, 'philip': 1, 'swear': 1, 'by': 1})\n",
      "b Counter({',': 4, 'the': 3, 'prince': 2, 'and': 2, 'brands': 1, 'queen': 1, 'elizabeth': 1, 'charles': 1, 'philip': 1, 'swear': 1, 'by': 1, 'shop': 1, 'notebooks': 1, 'jackets': 1, 'more': 1, 'that': 1, 'royals': 1, 'can': 1, 't': 1, 'live': 1, 'without': 1, '.': 1})\n",
      "a Counter({'the': 5, ',': 4, 'prince': 2, 'and': 2, 'of': 2, 's': 2, 'brands': 1, 'queen': 1, 'elizabeth': 1, 'charles': 1, 'philip': 1, 'swear': 1, 'by': 1, 'shop': 1, 'notebooks': 1, 'jackets': 1, 'more': 1, 'that': 1, 'royals': 1, 'can': 1, 't': 1, 'live': 1, 'without': 1, '.': 1, 'cost': 1, 'trump': 1, 'aid': 1, 'freeze': 1, 'in': 1, 'trenches': 1, 'ukraine': 1, 'war': 1})\n",
      "b Counter({'the': 7, ',': 5, '.': 4, 'of': 4, 'prince': 2, 'and': 2, 's': 2, 'in': 2, 'ukraine': 2, 'war': 2, 'to': 2, 'brands': 1, 'queen': 1, 'elizabeth': 1, 'charles': 1, 'philip': 1, 'swear': 1, 'by': 1, 'shop': 1, 'notebooks': 1, 'jackets': 1, 'more': 1, 'that': 1, 'royals': 1, 'can': 1, 't': 1, 'live': 1, 'without': 1, 'cost': 1, 'trump': 1, 'aid': 1, 'freeze': 1, 'trenches': 1, 'lt': 1, 'ivan': 1, 'molchanets': 1, 'peeked': 1, 'over': 1, 'a': 1, 'parapet': 1, 'sand': 1, 'bags': 1, 'at': 1, 'front': 1, 'line': 1, 'next': 1, 'him': 1, 'was': 1, 'an': 1, 'empty': 1, 'helmet': 1, 'propped': 1, 'up': 1, 'trick': 1, 'snipers': 1, 'already': 1, 'perforated': 1, 'with': 1, 'multiple': 1, 'holes': 1})\n",
      "a Counter({'the': 7, '.': 6, ',': 5, 'of': 4, 's': 3, 'prince': 2, 'and': 2, 'in': 2, 'ukraine': 2, 'war': 2, 'to': 2, 'was': 2, 'an': 2, 'brands': 1, 'queen': 1, 'elizabeth': 1, 'charles': 1, 'philip': 1, 'swear': 1, 'by': 1, 'shop': 1, 'notebooks': 1, 'jackets': 1, 'more': 1, 'that': 1, 'royals': 1, 'can': 1, 't': 1, 'live': 1, 'without': 1, 'cost': 1, 'trump': 1, 'aid': 1, 'freeze': 1, 'trenches': 1, 'lt': 1, 'ivan': 1, 'molchanets': 1, 'peeked': 1, 'over': 1, 'a': 1, 'parapet': 1, 'sand': 1, 'bags': 1, 'at': 1, 'front': 1, 'line': 1, 'next': 1, 'him': 1, 'empty': 1, 'helmet': 1, 'propped': 1, 'up': 1, 'trick': 1, 'snipers': 1, 'already': 1, 'perforated': 1, 'with': 1, 'multiple': 1, 'holes': 1, 'i': 1, 'nba': 1, 'wife': 1, 'here': 1, 'how': 1, 'it': 1, 'affected': 1, 'my': 1, 'mental': 1, 'health': 1})\n",
      "b Counter({'.': 8, 'the': 7, ',': 7, 'of': 4, 'and': 3, 's': 3, 'in': 3, 'was': 3, 'an': 3, 'i': 3, 'prince': 2, 'that': 2, 't': 2, 'ukraine': 2, 'war': 2, 'a': 2, 'to': 2, 'nba': 2, 'wife': 2, 'it': 2, 'brands': 1, 'queen': 1, 'elizabeth': 1, 'charles': 1, 'philip': 1, 'swear': 1, 'by': 1, 'shop': 1, 'notebooks': 1, 'jackets': 1, 'more': 1, 'royals': 1, 'can': 1, 'live': 1, 'without': 1, 'cost': 1, 'trump': 1, 'aid': 1, 'freeze': 1, 'trenches': 1, 'lt': 1, 'ivan': 1, 'molchanets': 1, 'peeked': 1, 'over': 1, 'parapet': 1, 'sand': 1, 'bags': 1, 'at': 1, 'front': 1, 'line': 1, 'next': 1, 'him': 1, 'empty': 1, 'helmet': 1, 'propped': 1, 'up': 1, 'trick': 1, 'snipers': 1, 'already': 1, 'perforated': 1, 'with': 1, 'multiple': 1, 'holes': 1, 'here': 1, 'how': 1, 'affected': 1, 'my': 1, 'mental': 1, 'health': 1, 'felt': 1, 'like': 1, 'fraud': 1, 'being': 1, 'didn': 1, 'help': 1, 'fact': 1, 'nearly': 1, 'destroyed': 1, 'me': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 26740/26740 [00:03<00:00, 7569.31it/s]\n"
     ]
    }
   ],
   "source": [
    "news_vertical = news.vertical.drop_duplicates().reset_index(drop=True)\n",
    "vert_dict_inv = news_vertical.to_dict()\n",
    "vert_dict = {v:k+1 for k,v in vert_dict_inv.items()}\n",
    "\n",
    "news_subvertical = news.subvertical.drop_duplicates().reset_index(drop=True)\n",
    "subvert_dict_inv = news.subvertical.to_dict()\n",
    "subvert_dict = {v:k+1 for k,v in subvert_dict_inv.items()}\n",
    "\n",
    "news.title = news.title.apply(word_tokenize)\n",
    "news.abstract = news.abstract.apply(word_tokenize)\n",
    "\n",
    "word_cnt = Counter()\n",
    "word_cnt_all = Counter()\n",
    "\n",
    "for i in tqdm(range(len(news))):\n",
    "    word_cnt.update(news.loc[i]['title'])\n",
    "    word_cnt_all.update(news.loc[i]['title'])\n",
    "    if i < 3:\n",
    "        print('a', word_cnt_all)\n",
    "    else:\n",
    "        pass\n",
    "    word_cnt_all.update(news.loc[i]['abstract'])\n",
    "    if i < 3:\n",
    "        print('b', word_cnt_all)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "word_dict = {k: v+1 for k,v in zip(word_cnt, range(len(word_cnt)))}\n",
    "word_dict_all = {k: v+1 for k,v in zip(word_cnt_all, range(len(word_cnt_all)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93abf227",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_path, 'vert_dict.pkl'), 'wb') as f:\n",
    "    pickle.dump(vert_dict, f)\n",
    "    \n",
    "with open(os.path.join(output_path, 'subvert_dict.pkl'), 'wb') as f:\n",
    "    pickle.dump(subvert_dict, f)\n",
    "\n",
    "with open(os.path.join(output_path, 'word_dict.pkl'), 'wb') as f:\n",
    "    pickle.dump(word_dict, f)\n",
    "    \n",
    "with open(os.path.join(output_path, 'word_dict_all.pkl'), 'wb') as f:\n",
    "    pickle.dump(word_dict_all, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb250bf7",
   "metadata": {},
   "source": [
    "## Prepare embedding matrixs\n",
    "- embedding.npy : numpy array 파일\n",
    "- embedding_all.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46a75841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 842k/842k [03:19<00:00, 4.22kKB/s]\n"
     ]
    }
   ],
   "source": [
    "glove_path = download_and_extract_glove(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58d53319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:04, 92361.28it/s] \n",
      "400000it [00:05, 78075.08it/s] \n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, exist_word = load_glove_matrix(glove_path, word_dict, word_emb_dim)\n",
    "embedding_all_matrix, exist_all_word = load_glove_matrix(glove_path, word_dict_all, word_emb_dim)\n",
    "\n",
    "np.save(os.path.join(output_path, 'embedding.npy'), embedding_matrix)\n",
    "np.save(os.path.join(output_path, 'embedding_all.npy'), embedding_all_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a917b5",
   "metadata": {},
   "source": [
    "## Prepare uid2index.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b7e624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22034it [00:00, 721356.38it/s]\n"
     ]
    }
   ],
   "source": [
    "uid2index = {}\n",
    "\n",
    "with open(os.path.join(data_path, 'train', 'behaviors.tsv'), 'r') as f:\n",
    "    for l in tqdm(f):\n",
    "        uid = l.strip('\\n').split('\\t')[1]\n",
    "        if uid not in uid2index:\n",
    "            uid2index[uid] = len(uid2index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb77b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'uid2index.pkl'), 'wb') as f:\n",
    "    pickle.dump(uid2index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02081b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "embedding_exist_num": 22408,
        "embedding_exist_num_all": 37634,
        "subvert_num": 237,
        "uid2index": 5000,
        "vert_num": 17,
        "word_num": 23404,
        "word_num_all": 41074
       },
       "encoder": "json",
       "name": "utils_state",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "utils_state"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_state = {'vert_num': len(vert_dict),\n",
    "               'subvert_num': len(subvert_dict),\n",
    "               'word_num': len(word_dict),\n",
    "               'word_num_all': len(word_dict_all),\n",
    "               'embedding_exist_num': len(exist_word),\n",
    "               'embedding_exist_num_all': len(exist_all_word),\n",
    "               'uid2index': len(uid2index)}\n",
    "\n",
    "sb.glue('utils_state', utils_state)\n",
    "\n",
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c4cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_rec3713",
   "language": "python",
   "name": "recommender3713"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
