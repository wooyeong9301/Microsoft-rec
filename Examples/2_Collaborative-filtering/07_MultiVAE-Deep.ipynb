{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3b2268",
   "metadata": {},
   "source": [
    "# Variational Autoencoders for Colaborative Filtering on Movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc53e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.13 (default, Mar 29 2022, 02:18:16) \n",
      "[GCC 7.5.0]\n",
      "Pandas version: 1.3.5\n",
      "Tensorflow version: 2.7.3\n",
      "Keras version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import papermill as pm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.split_utils import min_rating_filter_pandas\n",
    "from recommenders.datasets.python_splitters import numpy_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "from recommenders.datasets.sparse import AffinityMatrix\n",
    "from recommenders.utils.python_utils import binarize\n",
    "from recommenders.models.vae.multinomial_vae import Mult_VAE\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f3d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 100\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '1m'\n",
    "\n",
    "# Model parameters\n",
    "HELDOUT_USERS = 600 # CHANGE FOR DIFFERENT DATASIZE\n",
    "INTERMEDIATE_DIM = 200\n",
    "LATENT_DIM = 70\n",
    "EPOCHS = 400\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# temporary Path to save the optimal model's weights\n",
    "tmp_dir = TemporaryDirectory()\n",
    "WEIGHTS_PATH = os.path.join(tmp_dir.name, \"mvae_weights.hdf5\")\n",
    "\n",
    "SEED = 98765"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee154568",
   "metadata": {},
   "source": [
    "## 1. Multi-VAE algorithm\n",
    "__Notations__: The notation used is described below.\n",
    "\n",
    "$u \\in \\{1,\\dots,U\\}$ 는 유저 인덱스, $i \\in \\{1,\\dots,I\\}$ 는 아이템 인덱스이다. 유저-아이템 상호작용 행렬은 클릭에 대한 행렬 $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$ 이고, 모델의 입력이다. $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ 유저 *u*의 각 아이템에 대한 클릭 횟수를 나타내는 BoW 벡터이다. 클릭 행렬은 이진 행렬이다. 일반적인 카운트 데이터로 확장하기 쉽다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243b265",
   "metadata": {},
   "source": [
    "__Multi-VAE Model__: \n",
    "\n",
    "각 유저 *u*에 대해, 표준 가우시안 사전확률로부터 $K$ 차원의 잠재 표현 $\\mathbf{z}_u$ 를 샘플링하는 것으로 모델이 시작한다. $\\mathbf{z}_u$ 는 $I$의 아이템들에 대해 확률 분포를 만들기 위해 비선형 함수 $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ 를 통해 변형된다. 클릭 히스토리 $\\mathbf{x}_u$ 에서, $\\pi (\\mathbf{z}_u)$ 에 대한 가정은 다음과 같다.\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),\\\\\n",
    "\\pi(\\mathbf{z}_u) = softmax\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$\n",
    "\n",
    "$\\mathbf{z}_u$ 는 가우시안으로 가정되는 근사 사후 확률 $q_\\phi (\\mathbf{z}_u | \\mathbf{x}_u )$ 로부터 샘플링되어야 한다. 경사도를 계산하기 위해, reparametrization trick을 사용하고 $\\mathbf{z}_u$ 는 아래 공식으로 게산된다. \n",
    "$$\n",
    "\\mathbf{z}_u = \\mathbf\\mu(x_u)+\\mathbf\\sigma(x_u) \\cdot \\mathbf\\epsilon\n",
    "$$\n",
    "\n",
    "where $\\mathbf\\epsilon \\sim \\mathcal{N}(0, \\mathbf{I})$ and $ \\mathbf\\mu(x_u), \\sigma(x_u)$ are calculated in encoder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54ec72a",
   "metadata": {},
   "source": [
    "한 명이 유저 $u$ 를 위한 Multi-VAE의 목표는 :\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model/ encoder), and  $p_\\theta$ refers to generative model/decoder. The first term is the log-likelohood and the second term is the  Kullback-Leibler divergence term.\n",
    "\n",
    "첫번째 항을 다룰 때, 원 논문에 제시된 다항의 log-우도 공식을 사용한다.\n",
    "\n",
    "$$\\log p_\\theta(\\mathbf{x}_u | \\mathbf{z}_u) = \\sum_{i} \\mathbf{x}_{ui}\\log \\mathbf{\\pi}_i (z_u) $$\n",
    "\n",
    "논문의 저자들은 직관적으로 내재적인 피드백 모델링에 더 좋은 다항 우도를 사용한다. 그리고 그들의 연구에서 증명된 것처럼 전통적으로 더 유명한 로지스틱이나 가우시안 우도보다 더 좋은 성능을 보여준다. 다항 우도를 사용함으로써 문제를 멀티 클래스 분류로 다룰 수 있다. 이 우도는 $x_u$ 의 0이 아닌 항목에 확률 밀도를 적용한 모델을 보상한다. 하지만 모델은 한정된 확률 밀도를 갖고 있다. 아이템들은 한정된 확률 밀도 안에서 경쟁한다. 모델은 더 클릭될만한 아이템에게 더 많은 확률 밀도를 할당한다.\n",
    "\n",
    "또한, $\\mathbf KL-divergence$ 는 정규화 텀으로 다뤄진다.[[Higgins et al, 2016]](https://openreview.net/pdf?id=Sy2fzU9gl), [[Burgess et al, 2018]](https://arxiv.org/pdf/1804.03599.pdf) : \n",
    "\n",
    "\n",
    "1. $\\mathbf \\beta = 1$ 이면 원래의 VAE 공식에 대응된다.[[Kingma et al, 2013]](https://arxiv.org/pdf/1312.6114.pdf)\n",
    "\n",
    "2. $\\mathbf \\beta > 1$ 이라고 하면, 원래의 VAE 공식보다 잠재 보틀넥에 더 강한 제약을 준다. These constraints limit the capacity of $\\mathbf z$, which, combined with the pressure to maximise the log likelihood of the training data $\\mathbf x$ under the model, should encourage the model to learn the most efficient representation of the data.\n",
    "\n",
    "3. Setting $\\mathbf \\beta<1$. 추천 시스템에서의 목표는 좋은 추천을 하는 것과 입력값이 초기의 입력값과 최대한 가깝도록 재구성하지 않는 것이다. 다른 말로 하면 로그 우도를 최대화하는 것이다. 만약 β<1로 설정하면, 사전 확률의 영향을 약화시키게 된다.  \n",
    "\n",
    "\n",
    "As a result, for the reasons explained above in 3., the KL-divergence is multiplied by the parameter $\\beta \\in [0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc86fed0",
   "metadata": {},
   "source": [
    "__Selecting β:__ 원 논문에 제시된 것처럼 $\\mathbf \\beta$ 를 선택하기 위해 간단한 경험적인 방법이 사용된다. 훈련 과정은 $\\mathbf \\beta = 0$에서 시작하고, 점차 1까지 증가한다. $\\mathbf KL$ 텀은 $\\mathbf \\theta , \\phi $ 에 대한 많은 그래디언트 업데이트에 걸쳐 서서히 어닐링된다. 최적의 $\\mathbf \\beta$ 는 모델의 성능이 정점을 찍었을 때 기록된다. 그러면 최적의 $\\mathbf \\beta$ 를 이용해 모델이 같은 어닐링 과정을 이용해 재학습되는데, $\\mathbf \\beta$ 는 이전 단계에서 찾아진 최적값에 도달했을 때 증가를 멈춘다.\n",
    "\n",
    "이 방법은 잘 먹히고, 서로 다른 값의 $\\mathbf \\beta$ 를 갖는 여러 모델을 학습시킬 필요가 없다는 이점이 있다. [[Bowman et al, 2015]](https://arxiv.org/pdf/1511.06349.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149b130",
   "metadata": {},
   "source": [
    "## 2. Keras implementation of Multi-VAE\n",
    "모델의 구현을 위해 Keras 패키지가 사용되었다.  Movielens 데이터는 클릭 행렬로 이진화되고, heldout 유저들 데이터에 기반해 검증된다.\n",
    "\n",
    "## 3. Data Preparation\n",
    "## 3.1 Load and split data\n",
    "데이터는 train / validation / test 셋으로 나눠진다.\n",
    "- 모든 유니크한 유저들은 training 유저와 heldout 유저로 나뉜다.\n",
    "- 위의 유저들의 목록들을 이용해 해당하는 training 데이터와 heldout 데이터가 얻어지고, 클릭 행렬로 변환된다.\n",
    "- 모델은 training 유저들의 전체 클릭 히스토리를 이용해 학습된다.\n",
    "- 평가를 위해서 모델에 대한 필요한 user-level 표현을 학습하기 위해 heldout 데이터(validation, test)의 일부 클릭 히스토리가 사용된다. 그러면 평가 메트릭이 모델이 heldout 데이터의 unseen 클릭 데이터의 남은 부분을 얼마나 잘 랭킹시키는지를 기준으로 계산된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d28ac60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5.78k/5.78k [00:03<00:00, 1.72kKB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = movielens.load_pandas_df(size=MOVIELENS_DATA_SIZE,\n",
    "                             header=['userID', 'itemID', 'rating', 'timestamp'])\n",
    "df.to_csv('Movielens_1m.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f96d3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3.0</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3.0</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0       1    1193     5.0  978300760\n",
       "1       1     661     3.0  978302109\n",
       "2       1     914     3.0  978301968\n",
       "3       1    3408     4.0  978300275\n",
       "4       1    2355     5.0  978824291"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Movielens_1m.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1dcd5",
   "metadata": {},
   "source": [
    "### Data Filtering\n",
    "아래 규칙을 지켜 데이터를 필터링한다.\n",
    "- 평점 3.5 이하의 데이터는 필터링한다. 유저로부터 3.5 이하의 평점을 받은 영화는 마지막 클릭 행렬에 포함되지 않는다. 이 필터링을 하지 않으면 최종 클릭 행렬은 엄청 희소할 것이다.\n",
    "- 영화를 5개 미만으로 클릭한 유저는 필터링된다.\n",
    "- 클릭되지 않은 영화는 필터링된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f613eed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575281, 4)\n"
     ]
    }
   ],
   "source": [
    "# Binarize the data\n",
    "data_preferred = data[data['rating'] > 3.5]\n",
    "print(data_preferred.shape)\n",
    "data_low_rating = data[data['rating'] <= 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "812c18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# users who clicked on at least 5 movies\n",
    "data = min_rating_filter_pandas(data_preferred, min_rating=5, filter_by='user')\n",
    "# movies that were clicked on by at least 1 user\n",
    "data = min_rating_filter_pandas(data, min_rating=1, filter_by='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b922f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 575272 watching events from 6034 users and 3533 movies (sparsity: 2.699%)\n"
     ]
    }
   ],
   "source": [
    "# obtain both usercnt and itemcnt after filtering\n",
    "usercnt = data[['userID']].groupby('userID', as_index=False).size()\n",
    "itemcnt = data[['itemID']].groupby('itemID', as_index=False).size()\n",
    "\n",
    "# compute sparsity after filtering\n",
    "sparsity = data.shape[0] / (usercnt.shape[0]*itemcnt.shape[0])\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (data.shape[0], usercnt.shape[0], itemcnt.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249289de",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "검증 셋에 600명의 유저, 테스트 셋에 600명의 유저, 훈련 셋에 나머지 유저를 할당   \n",
    "훈련 셋 유저들의 클릭 히스토리를 이용해 모델을 훈련시키기 때문에 검증 셋과 테스트 셋에 있는 영화들이 훈련 셋에 있는 영화들이어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceec4729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users : 6034\n",
      "Number of training users : 4834\n",
      "Number of validation users : 600\n",
      "Number of test users : 600\n"
     ]
    }
   ],
   "source": [
    "unique_users = sorted(data.userID.unique())\n",
    "np.random.seed(SEED)\n",
    "unique_users = np.random.permutation(unique_users)\n",
    "\n",
    "n_users = len(unique_users)\n",
    "train_users = unique_users[:(n_users - HELDOUT_USERS*2)]\n",
    "val_users = unique_users[(n_users - HELDOUT_USERS*2):(n_users-HELDOUT_USERS)]\n",
    "test_users = unique_users[(n_users-HELDOUT_USERS):]\n",
    "print('Number of unique users :', n_users)\n",
    "print('Number of training users :', len(train_users))\n",
    "print('Number of validation users :', len(val_users))\n",
    "print('Number of test users :', len(test_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e528523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training observations:  462827\n",
      "Number of validation observations:  57388\n",
      "Number of test observations:  55057\n"
     ]
    }
   ],
   "source": [
    "train_set = data.loc[data['userID'].isin(train_users)]\n",
    "val_set = data.loc[data['userID'].isin(val_users)]\n",
    "test_set = data.loc[data['userID'].isin(test_users)]\n",
    "print(\"Number of training observations: \", train_set.shape[0])\n",
    "print(\"Number of validation observations: \", val_set.shape[0])\n",
    "print(\"Number of test observations: \", test_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "064a6142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique movies that rated in training set 3497\n",
      "Number of validation observations after filtering:  57374\n",
      "Number of test observations after filtering:  55027\n"
     ]
    }
   ],
   "source": [
    "# Obtain list of unique movies used in training set\n",
    "unique_train_items = pd.unique(train_set['itemID'])\n",
    "print(\"Number of unique movies that rated in training set\", unique_train_items.size)\n",
    "\n",
    "# Keep only movies that used in training set\n",
    "val_set = val_set.loc[val_set['itemID'].isin(unique_train_items)]\n",
    "print(\"Number of validation observations after filtering: \", val_set.shape[0])\n",
    "test_set = test_set.loc[test_set['itemID'].isin(unique_train_items)]\n",
    "print(\"Number of test observations after filtering: \", test_set.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b92bf",
   "metadata": {},
   "source": [
    "## 3.2 Click matrix generation\n",
    "오직 0과 1로만 이루어진 클릭 행렬이 모델의 입력이 된다. 이 때 각 행은 유저를, 각 열은 영화를 표현한다. 결국 클릭 행렬은 유저의 선호도를 내포하고, 별로 좋아하지 않거나 보지 않은 영화는 0, 좋아한 영화는 1로 표시한다.   \n",
    "Training set은 모든 training 유저들의 전체 기록을 포함하는 클릭 행렬이다. 하지만 validation set과 test set은 훈련과 테스트 부분으로 나눠져야 한다.   \n",
    "`val_tr`은 유저마다 클릭 행렬에서 1로 표시된 영화의 75%를 포함한다. 나머지 25%는 `val_te`에 포함된다. test set에도 같은 규칙이 적용된다. `val_tr`은 각 에폭의 마지막에 모델의 입력으로 주어진다. 각 유저에게 모델에 의해 추천된 영화는 `reconstructed_val_tr`에 저장된다. 각 에폭에서 모델의 성능을 검증하기 위해 `NDCG@k` metric을 이용해 `reconstructed_val_tr`를 `val_te`와 비교한다.   \n",
    "최종 검증을 위해 `test_tr`과 `test_te`를 사용한다. 과정은 각 에폭에서의 검증과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5021e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4834, 3497) (600, 3497) (600, 3497)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the sparse matrix generation\n",
    "am_train = AffinityMatrix(df=train_set, items_list=unique_train_items)\n",
    "am_val = AffinityMatrix(df=val_set, items_list=unique_train_items)\n",
    "am_test = AffinityMatrix(df=test_set, items_list=unique_train_items)\n",
    "\n",
    "# Obtain the sparse matrix\n",
    "train_data, a, b = am_train.gen_affinity_matrix()\n",
    "val_data, val_map_users, val_map_items = am_val.gen_affinity_matrix()\n",
    "test_data, test_map_users, test_map_items = am_test.gen_affinity_matrix()\n",
    "print(train_data.shape, val_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "023020eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 4., 5., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 5., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da248555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split validation and test into training and testing parts\n",
    "val_data_tr, val_data_te = numpy_stratified_split(val_data, ratio=0.75, seed=SEED)\n",
    "test_data_tr, test_data_te = numpy_stratified_split(test_data, ratio=0.75, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f03b551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize data\n",
    "train_data = binarize(a=train_data, threshold=3.5)\n",
    "val_data = binarize(a=val_data, threshold=3.5)\n",
    "test_data = binarize(a=test_data, threshold=3.5)\n",
    "train_data\n",
    "\n",
    "val_data_tr = binarize(a=val_data_tr, threshold=3.5)\n",
    "# Save non-binary in separate object which will be used for calculating NDCG\n",
    "val_data_te_ratings = val_data_te.copy()\n",
    "val_data_te = binarize(a=val_data_te, threshold=3.5)\n",
    "\n",
    "test_data_tr = binarize(a=test_data_tr, threshold=3.5)\n",
    "# Save non-binary in separate object which will be used for calculating NDCG\n",
    "test_data_te_ratings = test_data_te.copy()\n",
    "test_data_te = binarize(a=test_data_te, threshold=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154f9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_rec3713",
   "language": "python",
   "name": "recommender3713"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
