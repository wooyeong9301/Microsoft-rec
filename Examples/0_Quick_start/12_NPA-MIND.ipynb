{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d9796a",
   "metadata": {},
   "source": [
    "# NPA : Neural News Recommendation with Personalized Attention (2019)\n",
    "https://jenn1won.tistory.com/19?category=1046828"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d5111",
   "metadata": {},
   "source": [
    "- NPA는 content-based 뉴스 추천 방법이다.\n",
    "- CNN을 이용해 뉴스 표현을 학습하고, 유저들이 클릭한 뉴스로부터 유저 표현을 학습한다.\n",
    "- word-level personalized attention으로 서로 다른 유저에 대한 중요 단어에 집중한다.\n",
    "- news-level personalized attention으로 서로 다른 유저에 대한 뉴스 클릭에 집중한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c8311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.13 (default, Mar 29 2022, 02:18:16) \n",
      "[GCC 7.5.0]\n",
      "Tensorflow version: 2.7.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import scrapbook as sb\n",
    "from tempfile import TemporaryDirectory\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
    "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
    "from recommenders.models.newsrec.models.npa import NPAModel\n",
    "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
    "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f896c948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 17.0k/17.0k [00:08<00:00, 2.05kKB/s]\n",
      "100%|█████████████████████████████████████| 9.84k/9.84k [00:04<00:00, 2.30kKB/s]\n",
      "100%|█████████████████████████████████████| 95.0k/95.0k [00:26<00:00, 3.55kKB/s]\n"
     ]
    }
   ],
   "source": [
    "tmpdir = TemporaryDirectory()\n",
    "data_path = tmpdir.name\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
    "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
    "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
    "yaml_file = os.path.join(data_path, \"utils\", r'npa.yaml')\n",
    "\n",
    "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set('demo')\n",
    "\n",
    "if not os.path.exists(train_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
    "    \n",
    "if not os.path.exists(valid_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
    "if not os.path.exists(yaml_file):\n",
    "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', os.path.join(data_path, 'utils'), mind_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9f680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HParams object with values {'support_quick_scoring': False, 'dropout': 0.2, 'attention_hidden_dim': 200, 'head_num': 4, 'head_dim': 100, 'filter_num': 400, 'window_size': 3, 'vert_emb_dim': 100, 'subvert_emb_dim': 100, 'gru_unit': 400, 'type': 'ini', 'user_emb_dim': 100, 'learning_rate': 0.0001, 'optimizer': 'adam', 'epochs': 5, 'batch_size': 32, 'show_step': 100000, 'title_size': 10, 'his_size': 50, 'data_format': 'news', 'npratio': 4, 'metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'word_emb_dim': 300, 'cnn_activation': 'relu', 'model_type': 'npa', 'loss': 'cross_entropy_loss', 'wordEmb_file': '/tmp/tmpxo2yo8ez/utils/embedding.npy', 'wordDict_file': '/tmp/tmpxo2yo8ez/utils/word_dict.pkl', 'userDict_file': '/tmp/tmpxo2yo8ez/utils/uid2index.pkl'}\n"
     ]
    }
   ],
   "source": [
    "# Create Hyper-parameters\n",
    "hparams = prepare_hparams(yaml_file, wordEmb_file=wordEmb_file,\n",
    "                         wordDict_file=wordDict_file,\n",
    "                         userDict_file=userDict_file,\n",
    "                         batch_size=32,\n",
    "                         epochs=5)\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66613cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = MINDIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bbf6682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 14:51:05.456662: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-11 14:51:05.518485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 14:51:05.522068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 14:51:05.522347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 14:51:05.871213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 14:51:05.871502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 14:51:05.871728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 14:51:05.871943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2038 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-07-11 14:51:06.004251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 14:51:06.004539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 14:51:06.004745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/qwer/anaconda3/envs/recommender3713/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "0it [00:00, ?it/s]/home/qwer/anaconda3/envs/recommender3713/lib/python3.7/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-07-11 14:51:07.693497: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2022-07-11 14:51:08.225314: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 302.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 14:51:08.225377: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 302.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "8874it [01:39, 89.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.5229, 'mean_mrr': 0.2328, 'ndcg@5': 0.2376, 'ndcg@10': 0.303}\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = NPAModel(hparams, iterator, seed=42)\n",
    "print(model.run_eval(valid_news_file, valid_behaviors_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5d6e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2022-07-11 14:57:29.764210: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.44GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 14:57:29.764260: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.44GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 14:57:30.012450: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 14:57:30.012506: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "1085it [01:40, 11.10it/s]2022-07-11 14:59:08.220119: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 370.03MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 14:59:08.220744: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 370.03MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 14:59:08.397896: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 14:59:08.397949: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "1086it [01:41, 10.74it/s]\n",
      "8874it [01:38, 90.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 1\n",
      "train info: logloss loss:1.5236308640537999\n",
      "eval info: group_auc:0.5719, mean_mrr:0.2487, ndcg@10:0.3322, ndcg@5:0.2671\n",
      "at epoch 1 , train time: 101.1 eval time: 102.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [01:38, 11.04it/s]\n",
      "8874it [01:38, 90.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 2\n",
      "train info: logloss loss:1.4091489926447087\n",
      "eval info: group_auc:0.5934, mean_mrr:0.2669, ndcg@10:0.3535, ndcg@5:0.2902\n",
      "at epoch 2 , train time: 98.4 eval time: 102.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [01:38, 11.04it/s]\n",
      "8874it [01:39, 89.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 3\n",
      "train info: logloss loss:1.349556202717249\n",
      "eval info: group_auc:0.5946, mean_mrr:0.2699, ndcg@10:0.358, ndcg@5:0.2926\n",
      "at epoch 3 , train time: 98.4 eval time: 103.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [01:37, 11.09it/s]\n",
      "8874it [01:36, 91.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 4\n",
      "train info: logloss loss:1.2976336348561732\n",
      "eval info: group_auc:0.5938, mean_mrr:0.2687, ndcg@10:0.3558, ndcg@5:0.2907\n",
      "at epoch 4 , train time: 98.0 eval time: 100.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [01:37, 11.11it/s]\n",
      "8874it [01:36, 91.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 5\n",
      "train info: logloss loss:1.2633124786955656\n",
      "eval info: group_auc:0.5958, mean_mrr:0.2698, ndcg@10:0.3564, ndcg@5:0.2915\n",
      "at epoch 5 , train time: 97.7 eval time: 100.5\n",
      "CPU times: user 8min 29s, sys: 20.3 s, total: 8min 49s\n",
      "Wall time: 16min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<recommenders.models.newsrec.models.npa.NPAModel at 0x7f8529883b10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4792f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8874it [01:38, 90.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.5958, 'mean_mrr': 0.2698, 'ndcg@5': 0.2915, 'ndcg@10': 0.3564}\n",
      "CPU times: user 40.2 s, sys: 2.73 s, total: 42.9 s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
    "print(res_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4aaa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "group_auc": 0.5958,
        "mean_mrr": 0.2698,
        "ndcg@10": 0.3564,
        "ndcg@5": 0.2915
       },
       "encoder": "json",
       "name": "res_syn",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "res_syn"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.glue('res_syn', res_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = os.path.join(data_path, \"model\")\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "model.model.save_weights(os.path.join(model_path, \"npa_ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c737e1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8874it [01:38, 90.48it/s]\n",
      "7538it [00:00, 70042.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Output prediction File\n",
    "group_impr_indexes, group_labels, group_preds = model.run_slow_eval(valid_news_file, valid_behaviors_file)\n",
    "\n",
    "with open(os.path.join(data_path, 'prediction.txt'), 'w') as f:\n",
    "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "        impr_index += 1\n",
    "        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
    "        pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
    "        f.write(' '.join([str(impr_index), pred_rank])+ '\\n')\n",
    "\n",
    "f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
    "f.write(os.path.join(data_path, 'prediction.txt'), arcname='prediction.txt')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f118e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_rec3713",
   "language": "python",
   "name": "recommender3713"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
