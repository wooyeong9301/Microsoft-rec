{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27ad1c4",
   "metadata": {},
   "source": [
    "### Attention\n",
    "https://hyen4110.tistory.com/31   \n",
    "seq2seq - https://hyen4110.tistory.com/30\n",
    "seq2seq의 핵심은 2개의 RNN을 encoder-decoder 아키텍쳐 형식으로 만드는 것이다. 입력 단어를 하나씩 읽어 정해진 차원의 벡터 표현을 언은 후, 이를 다시 입력값으로 하여 한 단어 한 단어 추출한다.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bbb2ca",
   "metadata": {},
   "source": [
    "# NAML : Neural News Recommendation with Attentive Multi-View Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29cd00",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac839d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.13 (default, Mar 29 2022, 02:18:16) \n",
      "[GCC 7.5.0]\n",
      "Tensorflow version: 2.7.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import scrapbook as sb\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tempfile import TemporaryDirectory\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
    "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
    "from recommenders.models.newsrec.models.naml import NAMLModel\n",
    "from recommenders.models.newsrec.io.mind_all_iterator import MINDAllIterator\n",
    "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c8c9c",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96f3f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 17.0k/17.0k [00:08<00:00, 2.00kKB/s]\n",
      "100%|█████████████████████████████████████| 9.84k/9.84k [00:05<00:00, 1.86kKB/s]\n",
      "100%|█████████████████████████████████████| 95.0k/95.0k [00:27<00:00, 3.49kKB/s]\n"
     ]
    }
   ],
   "source": [
    "tmpdir = TemporaryDirectory()\n",
    "data_path = tmpdir.name\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding_all.npy\")\n",
    "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
    "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict_all.pkl\")\n",
    "vertDict_file = os.path.join(data_path, \"utils\", \"vert_dict.pkl\")\n",
    "subvertDict_file = os.path.join(data_path, \"utils\", \"subvert_dict.pkl\")\n",
    "yaml_file = os.path.join(data_path, \"utils\", r'naml.yaml')\n",
    "\n",
    "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set('demo')\n",
    "\n",
    "if not os.path.exists(train_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
    "    \n",
    "if not os.path.exists(valid_news_file):\n",
    "    download_deeprec_resources(mind_url, \\\n",
    "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
    "if not os.path.exists(yaml_file):\n",
    "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
    "                               os.path.join(data_path, 'utils'), mind_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64637bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HParams object with values {'support_quick_scoring': True, 'dropout': 0.2, 'attention_hidden_dim': 200, 'head_num': 4, 'head_dim': 100, 'filter_num': 400, 'window_size': 3, 'vert_emb_dim': 100, 'subvert_emb_dim': 100, 'gru_unit': 400, 'type': 'ini', 'user_emb_dim': 50, 'learning_rate': 0.0001, 'optimizer': 'adam', 'epochs': 5, 'batch_size': 16, 'show_step': 100000, 'title_size': 30, 'body_size': 50, 'his_size': 50, 'vert_num': 17, 'subvert_num': 249, 'data_format': 'naml', 'npratio': 4, 'metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'word_emb_dim': 300, 'cnn_activation': 'relu', 'model_type': 'naml', 'dense_activation': 'relu', 'loss': 'cross_entropy_loss', 'wordEmb_file': '/tmp/tmpmjvrjmqp/utils/embedding_all.npy', 'wordDict_file': '/tmp/tmpmjvrjmqp/utils/word_dict_all.pkl', 'userDict_file': '/tmp/tmpmjvrjmqp/utils/uid2index.pkl', 'vertDict_file': '/tmp/tmpmjvrjmqp/utils/vert_dict.pkl', 'subvertDict_file': '/tmp/tmpmjvrjmqp/utils/subvert_dict.pkl'}\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(yaml_file, \n",
    "                          wordEmb_file=wordEmb_file,\n",
    "                          wordDict_file=wordDict_file, \n",
    "                          userDict_file=userDict_file,\n",
    "                          vertDict_file=vertDict_file, \n",
    "                          subvertDict_file=subvertDict_file,\n",
    "                          batch_size=16,\n",
    "                          epochs=5)\n",
    "print(hparams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ddce0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = MINDAllIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be82b9b",
   "metadata": {},
   "source": [
    "## Train the NAML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df14e650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 10:17:29.939048: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-11 10:17:30.018883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 10:17:30.043385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 10:17:30.043900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 10:17:30.583457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 10:17:30.583746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 10:17:30.583969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 10:17:30.584284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1930 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-07-11 10:17:30.902588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 10:17:30.902888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-11 10:17:30.903096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/qwer/anaconda3/envs/recommender3713/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "0it [00:00, ?it/s]/home/qwer/anaconda3/envs/recommender3713/lib/python3.7/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-07-11 10:17:33.148241: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "1it [00:02,  2.44s/it]2022-07-11 10:17:34.439669: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.80GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 10:17:34.440365: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.80GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "18709it [00:17, 1058.45it/s]\n",
      "0it [00:00, ?it/s]2022-07-11 10:17:50.155217: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 10:17:50.155806: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "7523it [00:24, 305.53it/s]\n",
      "7538it [00:00, 11322.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.4806, 'mean_mrr': 0.2097, 'ndcg@5': 0.2125, 'ndcg@10': 0.2762}\n"
     ]
    }
   ],
   "source": [
    "model = NAMLModel(hparams, iterator, seed=42)\n",
    "print(model.run_eval(valid_news_file, valid_behaviors_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df8e481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2022-07-11 10:18:56.189428: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 10:18:56.190077: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 10:18:56.414383: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1015.76MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 10:18:56.414430: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1015.76MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 10:18:56.435405: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-11 10:18:56.435451: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2171it [08:11,  4.42it/s]\n",
      "18709it [00:16, 1142.05it/s]\n",
      "7523it [00:24, 312.86it/s]\n",
      "7538it [00:00, 13457.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 1\n",
      "train info: logloss loss:1.4839619423375598\n",
      "eval info: group_auc:0.5882, mean_mrr:0.2579, ndcg@10:0.3486, ndcg@5:0.2853\n",
      "at epoch 1 , train time: 491.7 eval time: 44.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2171it [08:06,  4.46it/s]\n",
      "18709it [00:15, 1195.10it/s]\n",
      "7523it [00:23, 316.92it/s]\n",
      "7538it [00:00, 16017.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 2\n",
      "train info: logloss loss:1.403804251341598\n",
      "eval info: group_auc:0.6243, mean_mrr:0.2793, ndcg@10:0.3757, ndcg@5:0.3127\n",
      "at epoch 2 , train time: 486.7 eval time: 43.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2171it [08:10,  4.43it/s]\n",
      "18709it [00:16, 1138.49it/s]\n",
      "7523it [00:25, 300.39it/s]\n",
      "7538it [00:00, 13166.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 3\n",
      "train info: logloss loss:1.3555402696434664\n",
      "eval info: group_auc:0.6442, mean_mrr:0.29, ndcg@10:0.3875, ndcg@5:0.3247\n",
      "at epoch 3 , train time: 490.4 eval time: 45.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2171it [08:04,  4.49it/s]\n",
      "18709it [00:16, 1145.38it/s]\n",
      "7523it [00:24, 305.93it/s]\n",
      "7538it [00:00, 12218.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 4\n",
      "train info: logloss loss:1.3267070193380763\n",
      "eval info: group_auc:0.6438, mean_mrr:0.2919, ndcg@10:0.3874, ndcg@5:0.3242\n",
      "at epoch 4 , train time: 484.1 eval time: 44.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2171it [08:05,  4.47it/s]\n",
      "18709it [00:19, 945.95it/s] \n",
      "7523it [00:25, 295.44it/s]\n",
      "7538it [00:00, 8429.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 5\n",
      "train info: logloss loss:1.306584160677138\n",
      "eval info: group_auc:0.6462, mean_mrr:0.2926, ndcg@10:0.3878, ndcg@5:0.3241\n",
      "at epoch 5 , train time: 485.9 eval time: 49.5\n",
      "CPU times: user 28min 26s, sys: 1min 18s, total: 29min 44s\n",
      "Wall time: 44min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<recommenders.models.newsrec.models.naml.NAMLModel at 0x7f7554141050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_news_file, train_behaviors_file,valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5bd3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18709it [00:15, 1175.98it/s]\n",
      "7523it [00:23, 316.72it/s]\n",
      "7538it [00:00, 15311.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.6462, 'mean_mrr': 0.2926, 'ndcg@5': 0.3241, 'ndcg@10': 0.3878}\n"
     ]
    }
   ],
   "source": [
    "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
    "print(res_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1948f9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "group_auc": 0.6462,
        "mean_mrr": 0.2926,
        "ndcg@10": 0.3878,
        "ndcg@5": 0.3241
       },
       "encoder": "json",
       "name": "res_syn",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "res_syn"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.glue('res_syn', res_syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439dbed",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7769c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(data_path, 'model')\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "model.model.save_weights(os.path.join(model_path, 'naml_ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16111b4",
   "metadata": {},
   "source": [
    "## Output Prediction File\n",
    "This code segment is used to generate the prediction.zip file, which is in the same format in MIND Competition Submission Tutorial.\n",
    "Please change the MIND_type parameter to large if you want to submit your prediction to MIND Competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1534774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18709it [00:15, 1173.31it/s]\n",
      "7523it [00:24, 310.69it/s]\n",
      "7538it [00:00, 13872.37it/s]\n"
     ]
    }
   ],
   "source": [
    "group_impr_indexes, group_labels, group_preds = model.run_fast_eval(valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7edbcf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7538it [00:00, 100950.10it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, 'prediction.txt'), 'w') as f:\n",
    "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "        impr_index += 1\n",
    "        pred_rank = (np.argsort(np.argsort(preds)[::-1])+1).tolist()\n",
    "        pred_rank = '['+','.join([str(i) for i in pred_rank]) + ']'\n",
    "        f.write(' '.join([str(impr_index), pred_rank])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1527448",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
    "f.write(os.path.join(data_path, 'prediction.txt'), arcname='prediction.txt')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b1f19de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpmjvrjmqp'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff712717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_rec3713",
   "language": "python",
   "name": "recommender3713"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
