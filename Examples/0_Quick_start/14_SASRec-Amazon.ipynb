{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be5ce75",
   "metadata": {},
   "source": [
    "# SASRec & SSEPT\n",
    "트랜스포머를 사용하는 시퀀셜 추천의 종류. 유저가 이전에 구매했거나 둘러본 아이템들의 시퀀스로 표현되는 유저의 선호를 인코딩하기 위해 트랜스포머를 사용. CNN(Caser)이나 RNN(GRU4Rec, SLI-Rec 등)을 사용하는 대신 아이템 시퀀스의 새로운 표현을 생성하는 트랜스포머 기반의 인코더 사용.   \n",
    "- 바닐라 트랜스포머에 기반하였고 오직 아이템 시퀀스만 모델링하는 Self-Attentive Sequential Recommendation과\n",
    "- 아이템과 유저까지 모델링하는 Stochastic Shared Embedding based Personalized Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772640a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.13 (default, Mar 29 2022, 02:18:16) \n",
      "[GCC 7.5.0]\n",
      "Tensorflow version: 2.7.3\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import scrapbook as sb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tempfile import TemporaryDirectory\n",
    "from collections import defaultdict\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets.amazon_reviews import get_review_data\n",
    "from recommenders.datasets.split_utils import filter_k_core\n",
    "\n",
    "# Transformer based models\n",
    "from recommenders.models.sasrec.model import SASREC\n",
    "from recommenders.models.sasrec.ssept import SSEPT\n",
    "\n",
    "# Sampler form sequential prediction\n",
    "from recommenders.models.sasrec.sampler import WarpSampler\n",
    "from recommenders.models.sasrec.util import SASRecDataSet\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a27c7e",
   "metadata": {},
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b1f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "seed = 100\n",
    "\n",
    "data_dir = os.path.join('..', '..' ,'tests', 'resources', 'deeprec', 'sasrec')\n",
    "\n",
    "dataset = 'reviews_Electronics_5'\n",
    "\n",
    "lr = 0.001\n",
    "maxlen = 50              # maximum sequence length for each user\n",
    "num_blocks = 2           # number of transformer blocks\n",
    "hidden_units = 100       # number of units in the attention calculation\n",
    "num_heads = 1            # number of attention heads\n",
    "dropout_rate = 0.1\n",
    "l2_emb = 0.0             # L2 regularization coefficient\n",
    "num_neg_test = 100       # number of negative examples per positive example\n",
    "model_name = 'ssept'     # 'sasrec' or 'ssept'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59149c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_name = dataset + '.json'\n",
    "outfile = dataset + '.txt'\n",
    "\n",
    "reviews_file = os.path.join(data_dir, reviews_name)\n",
    "if not os.path.exists(reviews_file):\n",
    "    reviews_output = get_review_data(reviews_file)\n",
    "else:\n",
    "    reviews_output = os.path.join(data_dir, dataset+'.json_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bd54a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터 전 df는.... (1689188, 3)\n",
      "                 userID      itemID        time\n",
      "0         AO94DHGC771SJ  0528881469  1370131200\n",
      "1         AMO214LNFCEI4  0528881469  1290643200\n",
      "2        A3N7T0DY83Y4IG  0528881469  1283990400\n",
      "3        A1H8PY3QHMQQA0  0528881469  1290556800\n",
      "4        A24EV6RXELQZ63  0528881469  1317254400\n",
      "...                 ...         ...         ...\n",
      "1689183  A34BZM6S9L7QI4  B00LGQ6HL8  1405555200\n",
      "1689184  A1G650TTTHEAL5  B00LGQ6HL8  1405382400\n",
      "1689185  A25C2M3QF9G7OQ  B00LGQ6HL8  1405555200\n",
      "1689186   A1E1LEVQ9VQNK  B00LGQ6HL8  1405641600\n",
      "1689187  A2NYK9KWFMJV4Y  B00LGQ6HL8  1405209600\n",
      "\n",
      "[1689188 rows x 3 columns]\n",
      "필터 후 df는.... (347393, 3)\n",
      "                       userID      itemID        time\n",
      "1480967  A0251761JI35FM4C8VK2  B009NHAEXE  1359936000\n",
      "1397003  A0251761JI35FM4C8VK2  B008HD3CTI  1359936000\n",
      "1330225  A0251761JI35FM4C8VK2  B007SZ0EOW  1359936000\n",
      "599564   A0251761JI35FM4C8VK2  B002HK8TE0  1359936000\n",
      "718345   A0251761JI35FM4C8VK2  B0036Q7MV0  1359936000\n",
      "...                       ...         ...         ...\n",
      "1132730         AZZYW4YOE1B6E  B005G8CKEU  1358035200\n",
      "956522          AZZYW4YOE1B6E  B004HHICKC  1357776000\n",
      "1665280         AZZYW4YOE1B6E  B00FZHCR04  1386633600\n",
      "948746          AZZYW4YOE1B6E  B004GF8TIK  1377907200\n",
      "1014035         AZZYW4YOE1B6E  B004ROOCO0  1357776000\n",
      "\n",
      "[347393 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(data_dir, outfile)):\n",
    "    df = pd.read_csv(reviews_output, sep='\\t', names=['userID', 'itemID', 'time'])\n",
    "    print('필터 전 df는....', df.shape)\n",
    "    print(df)\n",
    "    df = filter_k_core(df, 10)\n",
    "    print('필터 후 df는....', df.shape)\n",
    "    print(df)\n",
    "    \n",
    "    user_set, item_set = set(df['userID'].unique()), set(df['itemID'].unique())\n",
    "    user_map = dict()\n",
    "    item_map = dict()\n",
    "    for u, user in enumerate(user_set):\n",
    "        user_map[user] = u+1\n",
    "    for i, item in enumerate(item_set):\n",
    "        item_map[item] = i+1\n",
    "        \n",
    "    df['userID'] = df['userID'].apply(lambda x:user_map[x])\n",
    "    df['itemID'] = df['itemID'].apply(lambda x:item_map[x])\n",
    "    df = df.sort_values(by=['userID', 'time'])\n",
    "    df.drop(columns=['time'], inplace=True)\n",
    "    df.to_csv(os.path.join(data_dir, outfile), sep='\\t', header=False, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269212f8",
   "metadata": {},
   "source": [
    "SASRec는 시퀀스 인풋과 시퀀스 타겟을 필요로 한다. 모델에 대한 인풋은 다음과 같다\n",
    "- user's item history as input to the transformer\n",
    "- user's item history shifted as target to the transformer(positive examples)\n",
    "- a sequence of items that are not equal to the positive examples(negative examples)\n",
    "\n",
    "유저에 대해 *N*개의 아이템이 있으면 *N-2*개의 아이템이 학습에 사용되고 나머지 2개는 각각 검증과 테스트를 위해 사용된다.   \n",
    "\n",
    "인풋 파일의 포맷은 다음과 같아야 한다.\n",
    "- 각 행은 정수로 변환된 user-id와 item-id를 갖고 있어야 한다.\n",
    "- 행들은 user-id와 상호작용 시간 순서로 정렬되어 있어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed5cb839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../tests/resources/deeprec/sasrec/reviews_Electronics_5.txt\n",
      "20247 users and 11589 items\n",
      "average sequence length : 15.157751765693684\n"
     ]
    }
   ],
   "source": [
    "input_file = os.path.join(data_dir, dataset+'.txt')\n",
    "print(input_file)\n",
    "\n",
    "data = SASRecDataSet(filename=input_file, col_sep='\\t')\n",
    "data.split()\n",
    "\n",
    "num_steps = int(len(data.user_train)/batch_size)\n",
    "cc = 0.0\n",
    "for u in data.user_train:\n",
    "    cc += len(data.user_train[u])\n",
    "print('{} users and {} items'.format(data.usernum, data.itemnum))\n",
    "print('average sequence length : {}'.format(cc/len(data.user_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e2253f",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b56df899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 16:28:56.360389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 16:28:56.364659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 16:28:56.365095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 16:28:56.365907: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-12 16:28:56.366513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 16:28:56.366774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 16:28:56.367074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 16:28:56.682275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 16:28:56.682527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 16:28:56.682740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-12 16:28:56.682942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1992 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "if model_name == 'sasrec':\n",
    "    model = SASREC(item_num=data.itemnum, seq_max_len=maxlen, num_blocks=num_blocks,\n",
    "                  embedding_dim=hidden_units, attention_dim=hidden_units, attention_num_heads=num_heads,\n",
    "                  dropout_rate=dropout_rate, conv_dims=[100, 100], l2_reg=l2_emb, num_neg_test=num_neg_test)\n",
    "    \n",
    "elif model_name == 'ssept':\n",
    "    model = SSEPT(item_num=data.itemnum, user_num=data.usernum, seq_max_len=maxlen,\n",
    "                  num_blocks=num_blocks, user_embedding_dim=10, item_embedding_dim=hidden_units,\n",
    "                  attention_dim=hidden_units, attention_num_heads=num_heads, dropout_rate=dropout_rate,\n",
    "                  conv_dims = [110, 110], l2_reg=l2_emb, num_neg_test=num_neg_test)\n",
    "                  # embedding_dim=hidden_units,  # optional\n",
    "        \n",
    "else:\n",
    "    print('Model-{} not found'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efae0c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recommenders.models.sasrec.ssept.SSEPT at 0x7f81fddf0650>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f942d",
   "metadata": {},
   "source": [
    "## Sampler\n",
    "Sampler는 각 배치에서 훈련 데이터로부터 negative samples를 만든다. 유저의 상호작용 히스토리 원본을 보는 것과 전혀 나타나지 않은 아이템들을 만드는 것에 의해 수행된다. Sampler는 원본 히스토리와 같은 길이의 negative items의 시퀀스를 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70557ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WarpSampler(data.user_train, data.usernum, data.itemnum, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15875f2",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "- The loss function is defined over all the negative and positive logits.\n",
    "- A mask has to be applied to indicate the non-zero items present in the output.\n",
    "- Also add the regularization loss here.\n",
    "- Having a train-step signature function can speed up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5675030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 0/158 [00:00<?, ?b/s]2022-07-12 16:44:29.134455: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5, test (NDCG@10: 0.299637104966323, HR@10: 0.4957)\n",
      "Time cost for training is 2.79 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    t_test = model.train(data, sampler, num_epochs=epochs, batch_size=batch_size, lr=lr, val_epoch=6)\n",
    "\n",
    "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b54564ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ndcg@10': 0.299637104966323, 'Hit@10': 0.4957}\n"
     ]
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.299637104966323,
       "encoder": "json",
       "name": "ndcg@10",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "ndcg@10"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.4957,
       "encoder": "json",
       "name": "Hit@10",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "Hit@10"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_syn = {'ndcg@10': t_test[0], 'Hit@10': t_test[1]}\n",
    "print(res_syn)\n",
    "\n",
    "sb.glue(\"ndcg@10\", t_test[0])\n",
    "sb.glue(\"Hit@10\", t_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c81845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_rec3713",
   "language": "python",
   "name": "recommender3713"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
