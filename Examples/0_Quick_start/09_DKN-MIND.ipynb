{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86c125d3",
   "metadata": {},
   "source": [
    "# DKN : Deep Knowledge-Aware Network for News Recommendation\n",
    "DKN은 더 좋은 뉴스 추천을 위해 지식 그래프의 정보를 통합하는 딥러닝 모델이다. 특히, DKN은 지식 그래프 표현 학습의 방법으로 *TransX*를 사용하고, *KCNN*이라 불리는 CNN 프레임워크를 사용한다. 이를 통해 엔티티 임베딩과 단어 임베딩을 결합하고 뉴스 기사에 대한 최종 임베딩 벡터를 생성한다. attention-based neural scorer를 통해 CTR(Click-Through_Rate) 예측을 만든다.   \n",
    "\n",
    "## Properties of DKN\n",
    "- DKN은 전통적인 ID 기반의 협업 필터링보다는 CTR 예측을 위한 content-based 딥 모델이다.\n",
    "- It makes use of knowledge entities and common sense in news content via joint learning from semantic-level and knowledge-level representations of news articles.\n",
    "- DKN은 attention 모듈을 이용하여 사용자의 집계된 과거 표현을 동적으로 계산한다.\n",
    "\n",
    "## Data format\n",
    "- training / validation / test files : The format is:   \n",
    "`[label] [userid] [CandidateNews]%[impressionid]`   \n",
    "e.g. `1 train_U1 N1%0`   \n",
    "이 파일들의 각 줄은 한 인스턴스를 대변한다. `Impressionid`는 impression 세션에서 퍼포먼스를 평가하기 위해 사용된다. 평가 중에만 사용되며, 훈련 데이터에 대해서는 0으로 세팅한다.   \n",
    "- user history file : The format is:   \n",
    "`[Userid] [newsid1, newsid2, ...]`   \n",
    "이 파일의 각 줄은 유저의 클릭 히스토리를 대변한다. config 파일에서 `history_size` 파라미터 : 유저의 클릭 히스토리로 사용할 최대치를 설정해야 한다. 만약 유저의 클릭 히스토리가 파라미터보다 크면 마지막 수를 자동적으로 유지하고, 클릭 히스토리가 파라미터보다 작으면 자동적으로 0을 패딩한다.   \n",
    "- document feature file : The format is:   \n",
    "`[Newsid] [w1, w2, ..., wk] [e1, e2, ..., ek]`   \n",
    "이 파일엔 뉴스 기사들의 단어와 엔티티 특성이 들어있다.\n",
    "- word embedding / entity embedding / context embedding files:\n",
    "사전학습된 임베딩들의 `*.npy` 파일들이다. 각 파일은 [n+1, k]의 2차원 행렬이고, n은 해쉬 딕셔너리의 단어들(엔티티들)의 수이고 k는 임베딩의 차원의 수이다.\n",
    "\n",
    "In this experiment, we used GloVe[4] vectors to initialize the word embedding. We trained entity embedding using TransE[2] on knowledge graph and context embedding is the average of the entity's neighbors in the knowledge graph.\n",
    "\n",
    "## MIND dataset\n",
    "이 노트에선 MIND 데이터셋의 일부분-*MIND demo*-만 사용합니다. 5000명의 유저, 9432건의 뉴스기사와 6134개의 imporession logs를 다룹니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc03052",
   "metadata": {},
   "source": [
    "## Global Settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fdab46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.13 (default, Mar 29 2022, 02:18:16) \n",
      "[GCC 7.5.0]\n",
      "Tensorflow version: 2.7.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import scrapbook as sb\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources, prepare_hparams\n",
    "from recommenders.models.deeprec.models.dkn import DKN\n",
    "from recommenders.models.deeprec.io.dkn_iterator import DKNTextIterator\n",
    "\n",
    "print('System version: {}'.format(sys.version))\n",
    "print('Tensorflow version: {}'.format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cfdb3",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24087ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 11.3k/11.3k [00:06<00:00, 1.86kKB/s]\n"
     ]
    }
   ],
   "source": [
    "tmpdir = TemporaryDirectory()\n",
    "data_path = os.path.join(tmpdir.name, 'mind-demo-dkn')\n",
    "\n",
    "yaml_file = os.path.join(data_path, r'dkn.yaml')\n",
    "train_file = os.path.join(data_path, r'train_mind_demo.txt')\n",
    "valid_file = os.path.join(data_path, r'valid_mind_demo.txt')\n",
    "test_file = os.path.join(data_path, r'test_mind_demo.txt')\n",
    "\n",
    "news_feature_file = os.path.join(data_path, r'doc_feature.txt')\n",
    "user_history_file = os.path.join(data_path, r'user_history.txt')\n",
    "\n",
    "wordemb_file = os.path.join(data_path, r'word_embeddings_100.npy')\n",
    "entityemb_file = os.path.join(data_path, r'TransE_entity2vec_100.npy')\n",
    "contextemb_file = os.path.join(data_path, r'TransE_context2vec_100.npy')\n",
    "\n",
    "if not os.path.exists(yaml_file):\n",
    "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/deeprec/', tmpdir.name, 'mind-demo-dkn.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3a5e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TemporaryDirectory '/tmp/tmp6vr48dhj'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48d5830",
   "metadata": {},
   "source": [
    "## Create Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c32770bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HParams object with values {'use_entity': True, 'use_context': True, 'cross_activation': 'identity', 'user_dropout': False, 'dropout': [0.0], 'attention_dropout': 0.0, 'load_saved_model': False, 'fast_CIN_d': 0, 'use_Linear_part': False, 'use_FM_part': False, 'use_CIN_part': False, 'use_DNN_part': False, 'init_method': 'uniform', 'init_value': 0.1, 'embed_l2': 1e-06, 'embed_l1': 0.0, 'layer_l2': 1e-06, 'layer_l1': 0.0, 'cross_l2': 0.0, 'cross_l1': 0.0, 'reg_kg': 0.0, 'learning_rate': 0.0005, 'lr_rs': 1, 'lr_kg': 0.5, 'kg_training_interval': 5, 'max_grad_norm': 2, 'is_clip_norm': 0, 'dtype': 32, 'optimizer': 'adam', 'epochs': 10, 'batch_size': 64, 'enable_BN': True, 'show_step': 10000, 'save_model': False, 'save_epoch': 2, 'write_tfevents': False, 'train_num_ngs': 4, 'need_sample': True, 'embedding_dropout': 0.0, 'EARLY_STOP': 100, 'min_seq_length': 1, 'slots': 5, 'cell': 'SUM', 'doc_size': 10, 'history_size': 50, 'word_size': 12600, 'entity_size': 3987, 'data_format': 'dkn', 'metrics': ['auc'], 'pairwise_metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'method': 'classification', 'activation': ['sigmoid'], 'attention_activation': 'relu', 'attention_layer_sizes': 100, 'dim': 100, 'entity_dim': 100, 'transform': True, 'filter_sizes': [1, 2, 3], 'layer_sizes': [300], 'model_type': 'dkn', 'num_filters': 100, 'loss': 'log_loss', 'news_feature_file': '/tmp/tmpq_oazahs/mind-demo-dkn/doc_feature.txt', 'user_history_file': '/tmp/tmpq_oazahs/mind-demo-dkn/user_history.txt', 'wordEmb_file': '/tmp/tmpq_oazahs/mind-demo-dkn/word_embeddings_100.npy', 'entityEmb_file': '/tmp/tmpq_oazahs/mind-demo-dkn/TransE_entity2vec_100.npy', 'contextEmb_file': '/tmp/tmpq_oazahs/mind-demo-dkn/TransE_context2vec_100.npy'}\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history_size = 50\n",
    "batch_size = 64\n",
    "\n",
    "hparams = prepare_hparams(yaml_file, news_feature_file=news_feature_file,\n",
    "                         user_history_file=user_history_file,\n",
    "                         wordEmb_file=wordemb_file,\n",
    "                         entityEmb_file=entityemb_file,\n",
    "                         contextEmb_file=contextemb_file,\n",
    "                         epochs=epochs,\n",
    "                         history_size=history_size,\n",
    "                         batch_size=batch_size)\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c2e03",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09319342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qwer/anaconda3/envs/recommender3713/lib/python3.7/site-packages/recommenders/models/deeprec/models/dkn.py:309: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  training=self.is_train_stage,\n",
      "/home/qwer/anaconda3/envs/recommender3713/lib/python3.7/site-packages/keras/legacy_tf_layers/normalization.py:455: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "/home/qwer/anaconda3/envs/recommender3713/lib/python3.7/site-packages/recommenders/models/deeprec/models/dkn.py:197: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  training=self.is_train_stage,\n",
      "2022-07-08 10:19:56.319022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 10:19:56.319321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 10:19:56.319513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 10:19:56.319734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 10:19:56.319935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 10:19:56.320110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1866 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = DKN(hparams, DKNTextIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c63ee91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389962"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e5b02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.run_eval(valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02526842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7169/902749761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/recommender3713/lib/python3.7/site-packages/recommenders/models/deeprec/models/base_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_file, valid_file, test_file)\u001b[0m\n\u001b[1;32m    463\u001b[0m                 \u001b[0mdata_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             ) in self.iterator.load_data_from_file(train_file):\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0mstep_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_data_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_tfevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender3713/lib/python3.7/site-packages/recommenders/models/deeprec/models/base_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, feed_dict)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             ],\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         )\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender3713/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 971\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender3713/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1194\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender3713/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1374\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender3713/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1378\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender3713/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1362\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1364\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender3713/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_file, valid_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a76243",
   "metadata": {},
   "source": [
    "## Evaluate the DKN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "759c5a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.5968, 'group_auc': 0.5654, 'mean_mrr': 0.1816, 'ndcg@5': 0.1819, 'ndcg@10': 0.244}\n"
     ]
    }
   ],
   "source": [
    "res = model.run_eval(test_file)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4659410",
   "metadata": {},
   "source": [
    "fit 후 성능이 오르긴 올랐다?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76049d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "auc": 0.5968,
        "group_auc": 0.5654,
        "mean_mrr": 0.1816,
        "ndcg@10": 0.244,
        "ndcg@5": 0.1819
       },
       "encoder": "json",
       "name": "res",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "res"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.glue('res', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216770f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_rec3713",
   "language": "python",
   "name": "recommender3713"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
